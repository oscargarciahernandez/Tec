{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JupyterNotebook de la App para Electrobuzz\n",
    "\n",
    "## Intro\n",
    "\n",
    "En este cuaderno se pretende ir añadiendo todos los avances relativos al proyecto del desarrollo de la App para la descarga de música mediante Electrobuzz-Cosmobox. Cabe mencionar que este proyecto no está pensado para realizar un web-scrapping ilícito. Lo que se pretende mediante este programa es agilizar el proceso de descarga de música de Electrobuzz, pero teniendo en cuenta que es necesario contar con una cuenta de Cosmobox para ello. Tambien se pretende aprender a programar un scraper en python y hacer una pequeña interfaz de usuario que pueda acabar en convertirse en un ejecutable, QUIERO APRENDER A HACER SOFTWARE, PERO SOFTWARE CACHARRO. \n",
    "\n",
    "## Fundamentos\n",
    "\n",
    "En principio esta app se basará en realizar peticiones mediante el paquete requests. Se ha planteado realizar el trabajo inicial en 3 rondas de peticiones. \n",
    "\n",
    "En primera instancia todos las urls de todos los albumes disponibles en Electrobuzz. \n",
    "Una vez se consiga tener un listado de todos los links se pretende realizar una seguna ronda de requests que se encarge de completar la información de cada album, asi como Artista, Remixers, tamaño de la descarga y SOBRE TODO comprobar que exista el link de descarga de Cosmobox (existen albumes que no estan disponibles para descargar en Cosmobox y por lo tanto no son accesibles para nosotros). \n",
    "En la tercera ronda de requests se pretende comprobar que el link de Cosmobox no está caído (Hay  bastantes links que no funcionan).\n",
    "\n",
    "Con toda esta informacion se pasará a crear una interfaz empleando el paquete tkinter, la cual debe contar con un motor de busqueda dentro de toda la información de electrobuzz que nos permita rápidamente seleccionar los albumes que se quieren descargar. Sería interensante que dentro de este motor de busqueda se pudiera filtrar por nombre, sello, fecha, etc, para agilizar la labor de buscar la mñusica que nos apetezca. \n",
    "\n",
    "Dentro de la interfaz de tkinter habrá un botón para actualizar la información contenida en el software, como un método para tener al día todos los realeases de la página... Aunque tambien se podría realizar una actualización de manera automática. \n",
    "\n",
    "Debe ser sencillo selecionar la música que queremos descargar, igual añadimos un click marker y un botón de descarga al final de la página. Ya veré. Este paso no se si se realizará con requests (espero que si) o con Selenium... ambos tienen sus ventajas y desventajas. \n",
    "\n",
    "\n",
    "A continuación voy a añadir las librerias que voy empleando. Destacando requests y BeautifulSoup. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "import shutil\n",
    "import numpy as np\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problemas detectados\n",
    "\n",
    "El primero y yo creo que más importante es que los cabrones de Electrobuzz no dejan realizar scraping... Esto se puede confirmar viendo el archivo robot.txt de la página web. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Robot.txt de la página Electrobuzz](img_jupyter/robot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El asterísco en User-Agent siginifica que no se permiten spyders, crawlers y compañia. Por lo tanto intentarán bloquear cualquier comportamiento que sea similar al de un boot, por ejemplo, muchas requests en poco tiempo, o muchas requests iguales. Una vez han detectado a un boot lo siguiente que hacen es bloquear la IP que está realizando las peticiones. La IP la marca tu router, pa entendernos, por lo tanto hay que usar VPN o proxies. Investigando un poquito llegue a la conclusión de que iba a ser más fácil incluir el método de cambiar de proxies, sobre todo porque el paquete requests ya incluye métodos para fijar una proxie. \n",
    "\n",
    "## Buscar y cambiar proxy\n",
    "\n",
    "Para esto es necesario saber que las proxies no son fijas, es decir, las proxies son puntos de conexion que no siempre se encuentran disponibles por ello es necesario ir actualizando la lista de proxies a las que vamos a conectarnos. Para ello yo voy a usar una página web que ofrece un servicio de proxies gratuitas. \n",
    "\n",
    "Creo una función que devuelve las proxies encontradas en la página web. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ip': u'82.85.185.185', 'port': u'49788'},\n",
       " {'ip': u'182.253.101.59', 'port': u'51124'},\n",
       " {'ip': u'79.142.63.186', 'port': u'63141'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_proxies():   \n",
    "   \n",
    "  proxies_req = requests.get('https://www.sslproxies.org/')\n",
    "\n",
    "\n",
    "  soup = BeautifulSoup(proxies_req.content, 'html.parser')\n",
    "  proxies_table = soup.find(id='proxylisttable')\n",
    "  \n",
    "  proxies=[]\n",
    "\n",
    "  # Save proxies in the array\n",
    "  for row in proxies_table.tbody.find_all('tr'):\n",
    "    proxies.append({\n",
    "      'ip':   row.find_all('td')[0].string,\n",
    "      'port': row.find_all('td')[1].string\n",
    "    })\n",
    "\n",
    "  return proxies\n",
    "\n",
    "\n",
    "\n",
    "get_proxies() [:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es necesario entender como se deben incluir las proxies a las requests. Sin más, te lo demuestro con la función que he creado para poner en formato las proxies par que las entienda el paquete request. \n",
    "\n",
    "A esta función hay que meter como argumentos la lista de proxies que devuelte get_proxies() y el número dentro de la lista. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'http': 'http://118.173.233.134:60622',\n",
       " 'https': 'https://118.173.233.134:60622'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def set_proxi_for_req(proxies,n):\n",
    "    proxi_http='http://' + str(proxies[n]['ip'])+ ':' +proxies[n]['port']\n",
    "    proxi_https='https://' + str(proxies[n]['ip'])+ ':' +proxies[n]['port']\n",
    "    proxi1 = {'http': str(proxi_http), \"https\": str(proxi_https)}\n",
    "    return proxi1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "proxies=get_proxies()\n",
    "\n",
    "set_proxi_for_req(proxies, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ese es el formato que requiere el paquete requests para fijar las proxies y se introduce la siguiente manera. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requests.get('url', proxies= 'proxi en formato visto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nosotras lo vamos a utilizar asi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#requests.get('url', proxies= set_proxi_for_req(proxies,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
